<html>
  <head>
    <!-- Title -->
    <title>Publications - The Tensor Algebra Compiler (taco)</title>
    <!-- Compiled and minified CSS -->
    <link rel="stylesheet" href="stylesheets/collapsible.css">
    <!-- Compiled and minified JavaScript -->
    <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.98.2/js/materialize.min.js"></script>
          
    <!-- CSS and JavaScript -->
    <link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.indigo-red.min.css">
    <script defer src="https://code.getmdl.io/1.3.0/material.min.js"></script>
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Roboto:300,400,500,700" type="text/css">
    <link rel="stylesheet" href="stylesheets/style.css">


  </head>
  <body>
    <!-- Always shows a header, even in smaller screens. -->
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header">
      <header class="mdl-layout__header">
        <div class="mdl-layout__header-row">
          <!-- Title -->
          <a class="menu-title" href="index.html"> <span class="mdl-layout-title">The Tensor Algebra Compiler (taco)</span> </a>
          <!-- Add spacer, to align navigation to the right -->
          <div class="mdl-layout-spacer"></div>
          <!-- Navigation -->
          <nav class="mdl-navigation">
            <a class="mdl-navigation__link" href="docs/index.html">Docs</a>
            <a class="mdl-navigation__link" href="publications.html">Publications</a>
            <a class="mdl-navigation__link" href="codegen.html">Demo</a>
            <a class="mdl-navigation__link" href="https://github.com/tensor-compiler/taco">GitHub</a>
          </nav>
        </div>        
      </header>

      <main class="mdl-layout__content">
        <div class="page-content">
          <div class="mdl-grid">
            <!-- Three Line List with secondary info and action -->
            <div class="mdl-layout-spacer"></div>
            <div class="mdl-cell mdl-cell--9-col">
              <p class="mdl-typography mdl-typography--headline">Publications</p>
              <ul class="collapsible" data-collapsible="accordion">
                <li>
                  <div class="collapsible-header"><i class="material-icons">library_books</i>The Tensor Algebra Compiler &nbsp;<span class="mdl-typography--caption-color-contrast right">Fredrik Kjolstad, Shoaib Kamil, Stephen Chou, David Lugato, and Saman Amarasinghe</span></div>
                  <div class="collapsible-body">
                    <span>
                      <div class="mdl-grid" style="padding: 0px">
                      <div class="mdl-cell mdl-cell--6-col" style="margin-top: 0px; margin-bottom: 0px">
                      <a href="kjolstad-oopsla17-tensor-compiler.pdf"><button class="mdl-button mdl-js-button mdl-button--raised mdl-button--accent getpdf">Download Paper</button></a></div>
                      <div class="mdl-cell mdl-cell--6-col" style="margin-top: 0px; margin-bottom: 0px">
                      <a href="http://groups.csail.mit.edu/commit/presentations/2017/tensor-compiler.pdf"><button class="mdl-button mdl-js-button mdl-button--raised mdl-button--accent getpdf">Download Presentation</button></a></div>
                      </div>
                      <h5>Abstract</h5>
                        <div class="body-text"> 
  Tensor algebra is a powerful tool with applications in machine learning, data
  analytics, engineering and the physical sciences.  Tensors are often sparse
  and compound operations must frequently be computed in a single kernel for
  performance and to save memory.  Programmers are left to write kernels for
  every operation of interest, with different mixes of dense and sparse tensors
  in different formats.  The combinations are infinite, which makes it
  impossible to manually implement and optimize them all.  This paper
  introduces the first compiler technique to automatically generate kernels for
  any compound tensor algebra operation on dense and sparse tensors.  The
  technique is implemented in a C++ library called taco.  Its performance is
  competitive with best-in-class hand-optimized kernels in popular libraries,
  while supporting far more tensor operations.</div>
                      <div>
                      <h5>BibTex</h5>
                        <pre class="bibtex" ><code>@article{kjolstad:2017:taco,
 author = {Kjolstad, Fredrik and Kamil, Shoaib and Chou, Stephen and Lugato, David and Amarasinghe, Saman},
 title = {The Tensor Algebra Compiler},
 journal = {Proc. ACM Program. Lang.},
 issue_date = {October 2017},
 volume = {1},
 number = {OOPSLA},
 month = oct,
 year = {2017},
 issn = {2475-1421},
 pages = {77:1--77:29},
 articleno = {77},
 numpages = {29},
 url = {http://doi.acm.org/10.1145/3133901},
 doi = {10.1145/3133901},
 acmid = {3133901},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {code generation, iteration graphs, linear algebra, merge lattices, parallelism, performance, sparse data structures, tensor algebra, tensors}
}</code></pre>
                      </div>
                    </span>
                  </div>
                </li>
                <li>
                  <div class="collapsible-header"><i class="material-icons">library_books</i>taco: A Tool to Generate Tensor Algebra Kernels &nbsp;<span class="mdl-typography--caption-color-contrast right">Fredrik Kjolstad, Stephen Chou, David Lugato, Shoaib Kamil, and Saman Amarasinghe</span></div>
                  <div class="collapsible-body">
                    <span>
                      <div class="mdl-grid" style="padding: 0px">
                      <div class="mdl-cell mdl-cell--12-col" style="margin-top: 0px; margin-bottom: 0px">
                      <a href="http://tensor-compiler.org/taco-tools.pdf"><button class="mdl-button mdl-js-button mdl-button--raised mdl-button--accent getpdf">Download Paper</button></a></div>
                      <h5>Abstract</h5>
                        <div class="body-text">
  Tensor algebra is an important computational abstraction that is increasingly
  used in data analytics, machine learning, engineering, and the physical
  sciences. However, the number of tensor expressions is unbounded, which makes
  it hard to develop and optimize libraries. Furthermore, the tensors are often
  sparse (most components are zero), which means the code has to traverse
  compressed formats. To support programmers we have developed taco, a code
  generation tool that generates dense, sparse, and mixed kernels from tensor
  algebra expressions. This paper describes the taco web and command-line tools
  and discusses the benefits of a code generator over a traditional library.
  See also the demo video at tensor-compiler.org/ase2017.</div>
                      <div>
                      <h5>BibTex</h5>
                        <pre class="bibtex" ><code>@inproceedings{kjolstad:2017:tacotool, 
  author={Kjolstad, Fredrik and Chou, Stephen and Lugato, David and Kamil, Shoaib and Amarasinghe, Saman}, 
  booktitle={2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={taco: A Tool to Generate Tensor Algebra Kernels}, 
  year={2017}, 
  pages={943-948}, 
  keywords={data analysis;learning (artificial intelligence);mathematics computing;program compilers;software libraries;tensors;code generation tool;code generator;command-line tools;compressed formats;computational abstraction;data analytics;dense kernels;machine learning;mixed kernels;physical sciences;sparse kernels;taco web;tensor algebra expressions;tensor algebra kernels;tensor expressions;Indexes;Kernel;Libraries;Linear algebra;Tensile stress;Tools;Tensor algebra;compiler;linear algebra;sparse}, 
  doi={10.1109/ASE.2017.8115709}, 
  month={Oct}
}</code></pre>
                      </div>
                    </span>
                  </div>
                </li>
                <li>
                  <div class="collapsible-header"><i class="material-icons">library_books</i>Format Abstraction for Sparse Tensor Algebra Compilers &nbsp;<span class="mdl-typography--caption-color-contrast right">Stephen Chou, Fredrik Kjolstad, and Saman Amarasinghe</span></div>
                  <div class="collapsible-body">
                    <span>
                      <div class="mdl-grid" style="padding: 0px">
                      <div class="mdl-cell mdl-cell--12-col" style="margin-top: 0px; margin-bottom: 0px">
                      <a href="chou-oopsla18-taco-formats.pdf"><button class="mdl-button mdl-js-button mdl-button--raised mdl-button--accent getpdf">Download Paper</button></a></div>
                      <h5>Abstract</h5>
                        <div class="body-text">
  This paper shows how to build a sparse tensor algebra compiler that is
  agnostic to tensor formats (data layouts).  We develop an interface that
  describes formats in terms of their capabilities and properties, and show how
  to build a modular code generator where new formats can be added as plugins.
  We then describe six implementations of the interface that compose to form
  the dense, CSR/CSF, COO, DIA, ELL, and HASH tensor formats and countless
  variants thereof.  With these implementations at hand, our code generator can
  generate code to compute any tensor algebra expression on any combination of
  the aforementioned formats.
<br><br>
  To demonstrate our technique, we have implemented it in the taco tensor
  algebra compiler.  Our modular code generator design makes it simple to add
  support for new tensor formats, and the performance of the generated code is
  competitive with hand-optimized implementations.  Furthermore, by
  extending taco to support a wider range of formats specialized for
  different application and data characteristics, we can improve end-user 
  application performance.  For example, if input data is provided in the COO
  format, our technique allows computing a single matrix-vector multiplication
  directly with the data in COO, which is up to 3.6&times; faster than by
  first converting the data to CSR.</div>
                      <div>
                      <h5>BibTex</h5>
                        <pre class="bibtex" ><code>@article{chou:2018:formats,
 author = {Chou, Stephen and Kjolstad, Fredrik and Amarasinghe, Saman},
 title = {Format Abstraction for Sparse Tensor Algebra Compilers},
 journal = {Proc. ACM Program. Lang.},
 issue_date = {November 2018},
 volume = {2},
 number = {OOPSLA},
 month = oct,
 year = {2018},
 issn = {2475-1421},
 pages = {123:1--123:30},
 articleno = {123},
 numpages = {30},
 url = {http://doi.acm.org/10.1145/3276493},
 doi = {10.1145/3276493},
 acmid = {3276493},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {modular code generation, sparse tensor algebra compilation, tensor formats},
}</code></pre>
                      </div>
                    </span>
                  </div>
                </li>
                <li>
                  <div class="collapsible-header"><i class="material-icons">library_books</i>Sparse Tensor Algebra Optimizations with Workspaces &nbsp;<span class="mdl-typography--caption-color-contrast right">Fredrik Kjolstad, Peter Ahrens, Shoaib Kamil, and Saman Amarasinghe</span></div>
                  <div class="collapsible-body">
                    <span>
                      <div class="mdl-grid" style="padding: 0px">
                      <div class="mdl-cell mdl-cell--12-col" style="margin-top: 0px; margin-bottom: 0px">
                      <a href="https://arxiv.org/pdf/1802.10574.pdf"><button class="mdl-button mdl-js-button mdl-button--raised mdl-button--accent getpdf">Download Paper</button></a></div>
                      <h5>Abstract</h5>
                        <div class="body-text">
This paper shows how to optimize sparse tensor algebraic expressions by
introducing temporary tensors, called workspaces, into the resulting loop
nests.  We develop a new intermediate language for tensor operations called
concrete index notation that extends tensor index notation.  Concrete index
notation expresses when and where sub-computations occur and what tensor they
are stored into.  We then describe the workspace optimization in this language,
and how to compile it to sparse code by building on prior work in the
literature.
<br><br>
We demonstrate the importance of the optimization on several important sparse
tensor kernels, including sparse matrix-matrix multiplication (SpMM), sparse
tensor addition (SpAdd), and the matricized tensor times Khatri-Rao product
(MTTKRP) used to factorize tensors.  Our results show improvements over prior
work on tensor algebra compilation and brings the performance of these kernels
on par with state-of-the-art hand-optimized implementations.  For example, SpMM
was not supported by prior tensor algebra compilers, the performance of MTTKRP
on the nell-2 data set improves by 35%, and MTTKRP can for the first time have
sparse results.</div>
                      <div>
                      <h5>BibTex</h5>
                        <pre class="bibtex" ><code>@article{kjolstad:2018:workspaces,
 author = {Kjolstad, Fredrik and Ahrens, Peter and Kamil, Shoaib and Amarasinghe, Saman},
 title = {Sparse Tensor Algebra Optimizations with Workspaces},
 journal = {ArXiv e-prints},
 archivePrefix = "arXiv",
 eprint = {1802.10574},
 primaryClass = "cs.MS",
 keywords = {Computer Science - Mathematical Software, Computer Science - Programming Languages},
 year = 2018,
 month = apr,
 url = {https://arxiv.org/abs/1802.10574}
}</code></pre>
                      </div>
                    </span>
                  </div>
                </li>
              </ul>
            </div>
            <div class="mdl-layout-spacer"></div>
            </div>
        </div>
      </main>
      <footer class="mdl-mini-footer">
        <div class="mdl-mini-footer__right-section">
          <div>Icons made by <a href="http://www.freepik.com" title="Freepik">Freepik</a> from <a href="http://www.flaticon.com" title="Flaticon">www.flaticon.com</a> is licensed by <a href="http://creativecommons.org/licenses/by/3.0/" title="Creative Commons BY 3.0" target="_blank">CC 3.0 BY</a></div>
        </div>
        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
          ga('create', 'UA-93058524-1', 'auto');
          ga('send', 'pageview');
        </script>
      </footer>
    </div>
  </body>
</html>
