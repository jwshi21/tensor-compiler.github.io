<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../favicon.ico">
  
  <title>Computing on Tensors - Documentation - The Tensor Algebra Compiler (TACO)</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  <link href="../extra.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Computing on Tensors";
    var mkdocs_page_input_path = "computations.md";
    var mkdocs_page_url = "/computations/index.html";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../index.html" class="icon icon-home"> Documentation - The Tensor Algebra Compiler (TACO)</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../index.html">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">C++ Library</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../tensors/index.html">Defining Tensors</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="index.html">Computing on Tensors</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#specifying-tensor-algebra-computations">Specifying Tensor Algebra Computations</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#expressing-reductions">Expressing Reductions</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#performing-the-computation">Performing the Computation</a></li>
    

    <li class="toctree-l3"><a href="#delayed-execuation">Delayed Execuation</a></li>
    

    </ul>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Python Library</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../tutorial/index.html">Tutorial</a>
                </li>
                <li class="">
                    
    <a class="" href="../pytensors/index.html">Defining Tensors</a>
                </li>
                <li class="">
                    
    <a class="" href="../pycomputations/index.html">Computing on Tensors</a>
                </li>
                <li class="">
                    
    <a class="" href="../pyreference/index.html">Reference Manual</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Example Applications</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../scientific_computing/index.html">Scientific Computing: SpMV</a>
                </li>
                <li class="">
                    
    <a class="" href="../data_analytics/index.html">Data Analytics: MTTKRP</a>
                </li>
                <li class="">
                    
    <a class="" href="../machine_learning/index.html">Machine Learning: SDDMM</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../optimization/index.html">Strategies for Optimization</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">Documentation - The Tensor Algebra Compiler (TACO)</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
    
      
        
          <li>C++ Library &raquo;</li>
        
      
    
    <li>Computing on Tensors</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="specifying-tensor-algebra-computations">Specifying Tensor Algebra Computations</h1>
<p>Tensor algebra computations can be expressed in taco with tensor index notation, which at a high level describes how each element in the output tensor can be computed from elements in the input tensors. As an example, matrix addition can be expressed in index notation as </p>
<pre class="highlight"><code class="language-c++">A(i,j) = B(i,j) + C(i,j)</code></pre>

<p>where <code>A</code>, <code>B</code>, and <code>C</code> denote order-2 tensors (i.e. matrices) while <code>i</code> and <code>j</code> are index variables that represent abstract indices into the corresponding dimensions of the tensors. In words, the example above essentially states that, for every <code>i</code> and <code>j</code>, the element in the <code>i</code>-th row and <code>j</code>-th column of the <code>A</code> should be assigned the sum of the corresponding elements in <code>B</code> and <code>C</code>. Similarly, element-wise multiplication of three order-3 tensors can be expressed in index notation as follows</p>
<pre class="highlight"><code class="language-c++">A(i,j,k) = B(i,j,k) * C(i,j,k) * D(i,j,k)</code></pre>

<p>The syntax shown above corresponds to exactly what you would have to write in C++ with the taco library to define tensor algebra computations. Note, however, that prior to defining a tensor algebra computation, all index variables have to be declared. This can be done as shown below:</p>
<pre class="highlight"><code class="language-c++">IndexVar i, j, k;  // Declare index variables for previous example</code></pre>

<h2 id="expressing-reductions">Expressing Reductions</h2>
<p>In both of the previous examples, all of the index variables are used to index into both the output and the inputs. However, it is possible for an index variable to be used to index into the inputs only, in which case the index variable is reduced (summed) over. For instance, the following example </p>
<pre class="highlight"><code class="language-c++">y(i) = A(i,j) * x(j)</code></pre>

<p>can be rewritten with the summation more explicit as <script type="math/tex">y(i) = \sum_{j} A(i,j) \cdot x(j)</script> and demonstrates how matrix-vector multiplication can be expressed in index notation.</p>
<p>Note that, in taco, reductions are assumed to be over the smallest subexpression that captures all uses of the corresponding reduction variable. For instance, the following computation </p>
<pre class="highlight"><code class="language-c++">y(i) = A(i,j) * x(j) + z(i)</code></pre>

<p>can be rewritten with the summation more explicit as </p>
<p>
<script type="math/tex; mode=display">y(i) = \big(\sum_{j} A(i,j) \cdot x(j)\big) + z(i),</script>
</p>
<p>whereas the following computation </p>
<pre class="highlight"><code class="language-c++">y(i) = A(i,j) * x(j) + z(j)</code></pre>

<p>can be rewritten with the summation more explicit as </p>
<p>
<script type="math/tex; mode=display">y(i) = \sum_{j} \big(A(i,j) \cdot x(j) + z(i)\big).</script>
</p>
<h1 id="performing-the-computation">Performing the Computation</h1>
<p>Once a tensor algebra computation has been defined (and all of the inputs have been <a href="../tensors#initializing-tensors">initialized</a>), you can simply invoke the output tensor's <code>evaluate</code> method to perform the actual computation:</p>
<pre class="highlight"><code class="language-c++">A.evaluate();  // Perform the computation defined previously for output tensor A</code></pre>

<p>Under the hood, when you invoke the <code>evaluate</code> method, taco first invokes the output tensor's <code>compile</code> method to generate kernels that assembles the output indices (if the tensor contains any sparse dimensions) and that performs the actual computation. taco would then call the two generated kernels by invoking the output tensor's <code>assemble</code> and <code>compute</code> methods. You can manually invoke these methods instead of calling <code>evaluate</code> as demonstrated below:</p>
<pre class="highlight"><code class="language-c++">A.compile();   // Generate output assembly and compute kernels 
A.assemble();  // Invoke the output assembly kernel to assemble the output indices
A.compute();   // Invoke the compute kernel to perform the actual computation</code></pre>

<p>This can be useful if you want to perform the same computation multiple times, in which case it suffices to invoke <code>compile</code> once before the first time the computation is performed.</p>
<h1 id="delayed-execuation">Delayed Execuation</h1>
<p>It is also possible to skip using the compiler functions entirely. Once you attempt to modify or view the output tensor, taco will automatically invoke the compiler in order to generate the data. </p>
<p>It should be noted that in order to accurately time a computation, it is necessary to invoke the compiler functions directly since relying on the delayed execution mechanism can cause a lot of prior computations to be included in the timing.</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../tutorial/index.html" class="btn btn-neutral float-right" title="Tutorial">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../tensors/index.html" class="btn btn-neutral" title="Defining Tensors"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../tensors/index.html" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../tutorial/index.html" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script src="../search/require.js"></script>
      <script src="../search/search.js"></script>

</body>
</html>
