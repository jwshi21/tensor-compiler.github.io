<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../favicon.ico">
  
  <title>Computing on Tensors - Documentation - The Tensor Algebra Compiler (TACO)</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  <link href="../extra.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Computing on Tensors";
    var mkdocs_page_input_path = "pycomputations.md";
    var mkdocs_page_url = "/pycomputations/index.html";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="http://tensor-compiler.org" class="icon icon-home"> Tensor Algebra Compiler (TACO)</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../index.html">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Python Library</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../pytensors/index.html">Defining Tensors</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="index.html">Computing on Tensors</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#specifying-tensor-algebra-computations">Specifying Tensor Algebra Computations</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#expressing-reductions">Expressing Reductions</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#expressing-broadcasts">Expressing Broadcasts</a></li>
    

    <li class="toctree-l3"><a href="#expressing-transposes">Expressing Transposes</a></li>
    

    <li class="toctree-l3"><a href="#performing-the-computation">Performing the Computation</a></li>
    

    </ul>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Example Applications</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../scientific_computing/index.html">Scientific Computing: SpMV</a>
                </li>
                <li class="">
                    
    <a class="" href="../data_analytics/index.html">Data Analytics: MTTKRP</a>
                </li>
                <li class="">
                    
    <a class="" href="../machine_learning/index.html">Machine Learning: SDDMM</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../optimization/index.html">Strategies for Optimization</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../benchmarking/index.html">Guide to Benchmarking</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">C++ Library</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../tensors/index.html">Defining Tensors</a>
                </li>
                <li class="">
                    
    <a class="" href="../computations/index.html">Computing on Tensors</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="http://tensor-compiler.org"> Tensor Algebra Compiler (taco)</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
    
      
        
          <li>Python Library &raquo;</li>
        
      
    
    <li>Computing on Tensors</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="specifying-tensor-algebra-computations">Specifying Tensor Algebra Computations</h1>
<p>Tensor algebra computations can be expressed in TACO using tensor index
notation, which at a high level describes how each element in the result tensor
can be computed from elements in the operand tensors. As an example, matrix
addition can be expressed in index notation as </p>
<p>
<script type="math/tex; mode=display">A_{ij} = B_{ij} + C_{ij}</script>
</p>
<p>where <script type="math/tex">A</script>, <script type="math/tex">B</script>, and <script type="math/tex">C</script> denote two-dimensional tensors (i.e., matrices)
while <script type="math/tex">i</script> and <script type="math/tex">j</script> are index variables that represent abstract indices into
the corresponding dimensions of the tensors.  In plain English, the example
above essentially states that, for every <script type="math/tex">i</script> and <script type="math/tex">j</script>, the element in the
<script type="math/tex">i</script>-th row and <script type="math/tex">j</script>-th column of <script type="math/tex">A</script> should be assigned the sum of the
corresponding elements in <script type="math/tex">B</script> and <script type="math/tex">C</script>. Similarly, element-wise
multiplication of three tensors can be expressed in index notation as </p>
<p>
<script type="math/tex; mode=display">A_{ijk} = B_{ijk} \cdot C_{ijk} \cdot D_{ijk}.</script>
</p>
<p>To define the same computation using the TACO Python library, we can write very
similar code, with the main difference being that we also have to explicitly
declare the index variables beforehand:</p>
<pre><code class="python">i, j, k = pytaco.index_var(), pytaco.index_var(), pytaco.index_var()
A[i,j,k] = B[i,j,k] * C[i,j,k] * D[i,j,k]
</code></pre>

<p>This can also be rewritten more compactly as</p>
<pre><code class="python">i, j, k = pytaco.get_index_vars(3)
A[i,j,k] = B[i,j,k] * C[i,j,k] * D[i,j,k]
</code></pre>

<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>It is important to note that due to the complications that arise from
assembling sparse structures, we cannot have a tensor appear both on the left
hand side and the right hand side of an expression.  For all forms of index
expressions, we do not support indexing a tensor with the same index variable.
For example expressions such as <code>A[i,i]</code> are disallowed.</p>
</div>
<p>NOTE: When using scalars to express computations we must still use the square brackets to index the tensor. Since scalars are order-0 tensors, <code>None</code> must be passed into the index to specify that no <code>indexVar</code>s are used:</p>
<pre><code class="python">import pytaco as pt
i, j = pt.get_index_vars(2)

# Make a scalar value
A = pt.tensor(0)
# Make a compressed tensor of size 3x3
B = pt.tensor([3,3])

# Make some assignments
B[0, 0] = 1
B[1, 0] = 10

# We can sum the elements in B as follows. Notice we need to use None to tell 
# taco that A is a scalar.
A[None] = B[i, j]
</code></pre>

<h2 id="expressing-reductions">Expressing Reductions</h2>
<p>In both of the previous examples, all of the index variables are used to index into both the output and the inputs. However, it is possible for an index variable to be used to index into the inputs only, in which case the index variable is reduced (summed) over. For instance, the following example </p>
<pre><code class="c++">y(i) = A(i,j) * x(j)
</code></pre>

<p>can be rewritten with the summation more explicit as <script type="math/tex">y(i) = \sum_{j} A(i,j) \cdot x(j)</script> and demonstrates how matrix-vector multiplication can be expressed in index notation.</p>
<p>Note that, in taco, reductions are assumed to be over the smallest subexpression that captures all uses of the corresponding reduction variable. For instance, the following computation </p>
<pre><code class="c++">y(i) = A(i,j) * x(j) + z(i)
</code></pre>

<p>can be rewritten with the summation more explicit as </p>
<p>
<script type="math/tex; mode=display">y(i) = \big(\sum_{j} A(i,j) \cdot x(j)\big) + z(i),</script>
</p>
<p>whereas the following computation </p>
<pre><code class="c++">y(i) = A(i,j) * x(j) + z(j)
</code></pre>

<p>can be rewritten with the summation more explicit as </p>
<p>
<script type="math/tex; mode=display">y(i) = \sum_{j} \big(A(i,j) \cdot x(j) + z(i)\big).</script>
</p>
<h1 id="expressing-broadcasts">Expressing Broadcasts</h1>
<p>When using <code>indexVar</code>s, we must ensure that dimensions with the same <code>indexVar</code> are of the same size. Operations can be broadcast along outer dimensions assuming the inner dimensions are of the same size. For example:</p>
<pre><code class="python">import pytaco as pt
i, j, k = pt.get_index_vars(3)

# Make a compressed tensor of size 3x3
A = pt.tensor([3,3])
B = pt.tensor([3,3])

# Make a dense vector
C = pt.tensor([3], pt.dense)

# Make some assignments
C[0] = 1
B[0, 0] = 1

# We can add C to each row of B as follows:
A[i, j] =  B[i, j] + C[j]
</code></pre>

<p>The following, however, is not valid since the dimension of index j is of a different size for the different tensors:</p>
<pre><code class="python">import pytaco as pt
i, j, k = pt.get_index_vars(3)

# Make a compressed tensor of size 3x3
A = pt.tensor([3,3])
B = pt.tensor([3,3])

# Make a dense vector
C = pt.tensor([3,1], pt.dense)

# Make some assignments
C[1, 0] = 1
B[0, 0] = 1

# We can add C to each row of B as follows:
A[i, j] =  B[i, j] + C[i, j]
</code></pre>

<p>Taco currently does not support numpy-style broadcasting of singleton dimensions as evidenced by the snippet above. </p>
<h1 id="expressing-transposes">Expressing Transposes</h1>
<p>Transposes are not allowed during computations. The user will need to explicitly transpose a tensor themselves using <code>pt.tensor.transpose(new_ordering)</code> before doing the computation.</p>
<h1 id="performing-the-computation">Performing the Computation</h1>
<p>Once a tensor algebra computation has been defined (and all of the inputs have been <a href="../tensors#initializing-tensors">initialized</a>), you can simply invoke the output tensor's <code>evaluate</code> method to perform the actual computation:</p>
<pre><code class="c++">A.evaluate();  // Perform the computation defined previously for output tensor A
</code></pre>

<p>Under the hood, when you invoke the <code>evaluate</code> method, taco first invokes the output tensor's <code>compile</code> method to generate kernels that assembles the output indices (if the tensor contains any sparse dimensions) and that performs the actual computation. taco would then call the two generated kernels by invoking the output tensor's <code>assemble</code> and <code>compute</code> methods. You can manually invoke these methods instead of calling <code>evaluate</code> as demonstrated below:</p>
<pre><code class="c++">A.compile();   // Generate output assembly and compute kernels 
A.assemble();  // Invoke the output assembly kernel to assemble the output indices
A.compute();   // Invoke the compute kernel to perform the actual computation
</code></pre>

<p>This can be useful if you want to perform the same computation multiple times, in which case it suffices to invoke <code>compile</code> once before the first time the computation is performed.</p>
<p>It is also possible to skip using the compiler functions entirely. Once you attempt to modify or view the output tensor, taco will automatically invoke the compiler in order to generate the data. </p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../scientific_computing/index.html" class="btn btn-neutral float-right" title="Scientific Computing: SpMV">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../pytensors/index.html" class="btn btn-neutral" title="Defining Tensors"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-93058524-1', 'auto');
    ga('send', 'pageview');
  </script>

  <small>Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.</small>
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../pytensors/index.html" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../scientific_computing/index.html" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script src="../search/require.js"></script>
      <script src="../search/search.js"></script>

</body>
</html>
